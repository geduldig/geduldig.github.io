<!DOCTYPE html>
<title>Counting Words in Tweets</title>
<meta charset="utf-8">
<meta name="description" content="Counting words in tweets tutorial">
<meta name="keywords" content="twitter,python">
<meta name="author" content="Jonas Geduldig">
<link rel="stylesheet" href="css/style.css">
<link rel="stylesheet" href="css/foundation.css">

<body>
  <header>
    <h1>Mini-Tutorial: Counting Words in Tweets with Python</h1>
  </header>

  <article>
    <section>
      <header>
        <h2>The Challenge</h2>
      </header>
      <p>
Given a list of words, how do we count how many tweets contain each word? A word here is anything separated by whitespace. A word could be a hashtag. The tweet could be among those currently being tweeted, or the tweet could have happened in the past but not more than roughly a week in the past. Twitter does not retain older tweets.
      </p>
    </section>
    
    <section>
      <header>
        <h2>Twitter</h2>
      </header>
      <p>
Twitter supports two types of API's to interact with their service.  The two API's differ in the type of connection being made.  The Streaming API uses a continuous connection that doesn't close until the client breaks the connection. The REST API always closes the connection to the client after returning a result. Each API has many URL endpoints for making various types of requests.
      </p>
      <p>
We will the TwitterAPI package to simplify our Twitter requests.  The package supports all API endpoints and works with Python 2 and Python 3.  The endpoints we need are statuses/filter to get new tweets and search/tweets to get old tweets. But, before you can make requests, Twitter requires that you create an application and generate credentials on their website. You must provide these credentials when working with the API's.
      </p>
      <p>
        <pre>
          <code data-language='python'>
            from TwitterAPI import TwitterAPI

            api = TwitterAPI(API_KEY, API_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)
          </code>
        </pre>
      </p>
    </section>
    
    <section>
      <header>
        <h2>Counting New Tweets</h2>
      </header>
      <p>
Requesting new tweets with statuses/filter uses a continuous connection. So, we can keep getting tweets until either we or Twitter breaks the connection.  If we are careful, we can receive tweets forever.  This is how we get tweets using TwitterAPI.
      </p>
      <p>
        <pre>
          <code data-language='python'>
        		r = api.request('statuses/filter', {'track':'dog,cat,giraffe'})
      			for item in r.get_iterator():
    					print(item['text'])
          </code>
        </pre>
      </p>
      <p>
The above code downloads tweets that any of the words 'dog', 'cat', or 'giraffe'.  It will not run forever.  The most common cause for the loop to exit is the absense of data for a period of 90 seconds or longer.  Also, Twitter sometimes sends messages other than tweets, so we should code for that too.  Here is our next attempt.
      </p>
      <p>
        <pre>
          <code data-language='python'>
            total_skip = 0
            while True:
              skip = 0
            	try:
            		r = api.request('statuses/filter', {'track':'dog,cat,giraffe'})
            		while True:
            			for item in r.get_iterator():
            				if 'text' in item:
            					print(item['text'])
            				elif 'limit' in item:
            					skip = item['limit'].get('track')
            					print('\n\n\n*** Skipped %d tweets\n\n\n' % (total_skip + skip))
            				elif 'disconnect' in item:
            					raise Exception('Disconnect: %s' % item['disconnect'].get('reason'))
                except Exception as e:
              		print('*** MUST RECONNECT %s\n' % e)
          </code>
        </pre>
      </p>
    </section>
    

    <section>
      <header>
        <h2>Mining for Tweets</h2>
      </header>
      <p>
Twitter divides its API into two types of calls: REST API calls which return a result then close the connection, and Streaming API calls which keep returning results until you close the connection.  We employ <a href='https://github.com/geduldig/TwitterAPI'>TwitterAPI</a>, a lightweight Python package that supports both types of API calls.
      </p>
      <p>
Before you can mine tweets you must create your own Twitter application credentials.  Go to <a href='apps.twitter.com'>apps.twitter.com</a> and create an application and generate your API key and access token.  
      </p>
      <p>
        <i>Now we are ready to download tweets!</i>
      </p>
      <p>
You can familiarize yourself with the many API calls, or endpoints, that Twitter offers.  You will find them <a href='https://dev.twitter.com/docs/api/1.1'>here</a>.  Most endpoints have both required and optional parameters.  For example, the <a href='https://dev.twitter.com/docs/api/1.1/get/search/tweets'>search/tweets</a> endpoint has one required parameter <mark>q</mark> that sets the word or phrase for filtering downloaded tweets.  And, since it is a REST API endpoint, it downloads a finite number of tweets which you specify with the optional <mark>count</mark> parameter.
      </p>
      <p>
The following example uses <a href='https://dev.twitter.com/docs/api/1.1/post/statuses/filter'>statuses/filter</a>, a Streaming API endpoint that also downloads tweets.  Since it works over a continuous streaming connection it downloads tweets until you close the connection.  Alternatively, you may substitute any Twitter endpoint that downloads tweets, including <a href='https://dev.twitter.com/docs/api/1.1/get/search/tweets'>search/tweets</a>.  <mark>test_db</mark> is the name of the CouchDB database where the tweets are saved to.
      </p>
      <p>
        <pre>
          <code data-language='python'>
            from TweetStore import TweetStore
            from TwitterAPI.TwitterAPI import TwitterAPI

            # Your Twitter authentication credentials...
            API_KEY = XXX
            API_SECRET = XXX
            ACCESS_TOKEN = XXX
            ACCESS_TOKEN_SECRET = XXX

            storage = TweetStore('test_db')
            api = TwitterAPI(API_KEY, API_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)

            for item in api.request('statuses/filter', {'track':'pizza'}):
              if 'text' in item:
                print('%s -- %s\n' % (item['user']['screen_name'], item['text']))
                storage.save_tweet(item)
              elif 'message' in item:
                print('ERROR %s: %s\n' % (item['code'], item['message']))
          </code>
        </pre>
      </p>
      <p>
The parameters for the two endpoints are slightly different.  With <a href='https://dev.twitter.com/docs/api/1.1/post/statuses/filter'>statuses/filter</a> you specify filter words with <mark>track</mark> instead of <mark>q</mark>.  Or, if you would prefer to select tweets from a specific geographic location, this endpoint provides a <mark>locations</mark> parameter as well.  Just make sure you supply your credentials.
      </p>
      <p>
If everything is working for you up to this point, you are ready to retrieve tweets from the database.  But, before trying out the Python code below, you might want to see the results right away in a browser.  Type this url into your browser's address bar.
      </p>
      <p>
      <pre>
        <mark>
          http://127.0.0.1:5984/test_db/_design/twitter/_view/get_tweets
        </mark>
      </pre>
      </p>
      <p>
You should see in your browser the entire contents -- meta-data and all -- of the downloaded tweets.  Using Python it is just a little more work.  The following code prints only the text field from those tweets to the console.
        <pre>
          <code data-language='python'>
            from TweetStore import TweetStore

            storage = TweetStore('test_db')

            for doc in storage.get_tweets():
              print('%s\n' % doc.value['text'])
          </code>
        </pre>
      </p>
      <p>
That's it!  Try other Twitter endpoints that download tweets, such as <a href='https://dev.twitter.com/docs/api/1.1/get/statuses/user_timeline'>getting a user's timeline</a>.
      </p>
    </section>
  </article>
  
  <asside>
    <section>
      <h4>Python Packages</h4>
      <ul>
        <li>pip install <a href='https://github.com/geduldig/TwitterAPI'>TwitterAPI</a></li>
      </ul>
    </section>
    <section>
      <h4>Python Tutorial Source Code</h4>
      <ul>
        <li><a href='code/count-new-words.py'>count-new-words.py</a></li>
        <li><a href='code/count-old-words.py'>count-old-words.py</a></li>
      </ul>
    </section>
  </aside>
  
  <footer>
  	<img src='images/me.png' width='20px'>
    Jonas Geduldig, June 2014
  </fooer>

  <script src='js/highlight.pack.js'></script>

  <script>
    hljs.initHighlightingOnLoad();
  </script>
