<!DOCTYPE html>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<body>
	<div style='width:100%'>
		<video id='video' autoplay playsinline style='display:none'></video>
		<canvas id='canvas'></canvas>
	</div>

	<!-- SHADERS -->

	<script id='vshader' type='text/plain'>
		attribute vec2 position;
		void main(void) {
			gl_Position = vec4(position, 0, 1);
		}
	</script>

	<script id='fshader' type='text/plain'>
		precision mediump float;
		uniform sampler2D sampler0;
		uniform float width, height;
		void main() {
			vec2 st = vec2(gl_FragCoord.s/width, 1. - gl_FragCoord.t/height);
			vec3 rgb = texture2D(sampler0, st).rgb;
			gl_FragColor = vec4(rgb, 1.);
		}
	</script>

	<!-- MAIN PROGRAM -->	

	<script src='js/webglShader.js'></script>

	<script>
		console.log('VERSION 7');

		// -- DOM elements --

		const canvas = document.querySelector('#canvas');
		const video = document.querySelector('#video');
		const vs = document.querySelector('#vshader').textContent;
		const fs = document.querySelector('#fshader').textContent;

		// -- Setup shader program and variables --

		const gl = canvas.getContext('webgl', { preserveDrawingBuffer:true });
		const program = createProgram(gl, vs, fs);
		const width = gl.getUniformLocation(program, 'width');
		const height = gl.getUniformLocation(program, 'height');
		const sampler = gl.getUniformLocation(program, 'sampler0');
		const position = gl.getAttribLocation(program, 'position');
		const texture = createTexture(gl);
		const vertexBuffer = webglScreenQuad(gl);
		gl.uniform1i(sampler, 0);
		gl.enableVertexAttribArray(position);
		gl.vertexAttribPointer(position, vertexBuffer.itemSize, gl.FLOAT, false, 0, 0);
		let animID = undefined;

		// -- Stream camera --

		document.addEventListener('DOMContentLoaded', function(event) {
			startVideo(null);
		});
		
		function startVideo() {
			setupCamera(video, {video:true}, (err, stream) => {
				if (err)
					alert('WEBCAM FAILED: ' + err);
				else {
					resizeCanvas();
					startAnimation();
				}
			});
		}

		function resizeCanvas() {
			canvas.width = canvas.parentElement.clientWidth;
			canvas.height = canvas.width * (video.videoHeight / video.videoWidth);			
			gl.uniform1f(width, canvas.width);
			gl.uniform1f(height, canvas.height);
			gl.viewport(0, 0, canvas.width, canvas.height);
		}

		function startAnimation() {
			window.cancelAnimationFrame(animID);
			animID = window.requestAnimationFrame(function loop() {
				updateTexture(gl, texture, vertexBuffer, video);
				animID = window.requestAnimationFrame(loop);
			});
		}	
		
		// -- Camera media device --

		function setupCamera(video, constraints, callback) {
			if (navigator.mediaDevices === undefined || navigator.mediaDevices.getUserMedia === undefined) 
				onMediaFail('Camera not found.');
			else
				navigator.mediaDevices.getUserMedia(constraints)
					.then(onMediaStream)
					.catch(onMediaFail);

			function onMediaStream(stream) {
				video.srcObject = stream;
				video.onloadedmetadata = () => { 
					video.play(); 
					callback(null, stream); 
				};
			}

			function onMediaFail(err) {
				callback(err, null);
			}
		}

		// -- WebGL texture --

		function createTexture(gl) {
			let texture = gl.createTexture();
			gl.activeTexture(gl.TEXTURE0);
			gl.bindTexture(gl.TEXTURE_2D, texture);
			gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
			gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
			gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
			gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
			gl.bindTexture(gl.TEXTURE_2D, null);
			return texture;
		}

		function updateTexture(gl, texture, vertexBuffer, data) {
			gl.activeTexture(gl.TEXTURE0);
			gl.bindTexture(gl.TEXTURE_2D, texture);
			gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, data);
			gl.drawArrays(gl.TRIANGLE_STRIP, 0, vertexBuffer.numItems);
			gl.bindTexture(gl.TEXTURE_2D, null);
		}		


	</script>
</body>